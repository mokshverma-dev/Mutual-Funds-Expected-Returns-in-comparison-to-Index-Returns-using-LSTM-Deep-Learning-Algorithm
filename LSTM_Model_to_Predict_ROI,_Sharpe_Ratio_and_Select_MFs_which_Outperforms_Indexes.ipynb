{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "CeIfeaDAhKat",
        "outputId": "e1bacd51-e112-40ff-92a8-776fb5c6fd6a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'synthetic_mutual_fund_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2104775028.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load your training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"synthetic_mutual_fund_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Define sector benchmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'synthetic_mutual_fund_data.csv'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Load your training data\n",
        "df = pd.read_csv(\"synthetic_mutual_fund_data.csv\")\n",
        "\n",
        "# Define sector benchmarks\n",
        "sector_benchmarks = {\n",
        "    'Tech': 0.010,\n",
        "    'Finance': 0.005,\n",
        "    'Healthcare': 0.007\n",
        "}\n",
        "\n",
        "# Risk-free rate (monthly)\n",
        "risk_free_rate = 0.003\n",
        "window_size = 6\n",
        "\n",
        "# Output containers\n",
        "recommended_funds = []\n",
        "all_predictions = []\n",
        "\n",
        "# Group and process each Fund+Sector\n",
        "for (fund, sector), group in df.groupby(['Fund', 'Sector']):\n",
        "    group = group.reset_index(drop=True)\n",
        "    if len(group) < window_size + 3:\n",
        "        continue\n",
        "\n",
        "    # Create sequences\n",
        "    X, y_return, y_sharpe = [], [], []\n",
        "    for i in range(window_size, len(group) - 3):\n",
        "        past_returns = group['Monthly_Return'][i - window_size:i].values\n",
        "        future_returns = group['Monthly_Return'][i:i + 3].values\n",
        "        exp_ret = np.mean(future_returns)\n",
        "        sharpe = (exp_ret - risk_free_rate) / (np.std(future_returns) + 1e-6)\n",
        "        X.append(past_returns)\n",
        "        y_return.append(exp_ret)\n",
        "        y_sharpe.append(sharpe)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y_return = np.array(y_return)\n",
        "    y_sharpe = np.array(y_sharpe)\n",
        "\n",
        "    # Normalize input features\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X).reshape(X.shape)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, yret_train, yret_test, ysharpe_train, ysharpe_test = train_test_split(\n",
        "        X_scaled, y_return, y_sharpe, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Build LSTM model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(32, input_shape=(window_size, 1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(2))  # [Expected Return, Sharpe Ratio]\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Fit model\n",
        "    y_train_combined = np.vstack((yret_train, ysharpe_train)).T\n",
        "    model.fit(X_train.reshape(-1, window_size, 1), y_train_combined, epochs=30, batch_size=4, verbose=0)\n",
        "\n",
        "    # Predict\n",
        "    preds = model.predict(X_test.reshape(-1, window_size, 1))\n",
        "    for i in range(len(preds)):\n",
        "        pred_ret = preds[i][0]\n",
        "        pred_sharpe = preds[i][1]\n",
        "        all_predictions.append({\n",
        "            'Fund': fund,\n",
        "            'Sector': sector,\n",
        "            'Predicted_Return': round(pred_ret, 4),\n",
        "            'Predicted_Sharpe': round(pred_sharpe, 4)\n",
        "        })\n",
        "        if pred_ret > sector_benchmarks.get(sector, 0):\n",
        "            recommended_funds.append({\n",
        "                'Fund': fund,\n",
        "                'Sector': sector,\n",
        "                'Predicted_Return': round(pred_ret, 4),\n",
        "                'Predicted_Sharpe': round(pred_sharpe, 4)\n",
        "            })\n",
        "\n",
        "# Save results\n",
        "all_df = pd.DataFrame(all_predictions)\n",
        "recommended_df = pd.DataFrame(recommended_funds)\n",
        "\n",
        "all_df.to_csv(\"All_Funds_Prediction.csv\", index=False)\n",
        "recommended_df.to_csv(\"Recommended_Funds.csv\", index=False)\n",
        "\n",
        "print(\"- All_Funds_Prediction.csv saved.\")\n",
        "print(\"- Recommended_Funds.csv saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-IbMy2jqZ9D"
      },
      "outputs": [],
      "source": [
        "# This Code used to generate 3000 rows of synthetic mutual fund data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "funds = {\n",
        "    'Tech': ['FundA', 'FundD', 'FundF', 'FundG', 'FundH'],\n",
        "    'Finance': ['FundB', 'FundE', 'FundI', 'FundJ', 'FundK'],\n",
        "    'Healthcare': ['FundC', 'FundL', 'FundM', 'FundN', 'FundO']\n",
        "}\n",
        "\n",
        "sector_means = {'Tech': 0.01, 'Finance': 0.005, 'Healthcare': 0.007}\n",
        "sector_stds = {'Tech': 0.005, 'Finance': 0.003, 'Healthcare': 0.004}\n",
        "\n",
        "rows = []\n",
        "months_per_fund = 200  # so 5 funds * 3 sectors * 200 = 3000 rows\n",
        "\n",
        "for sector, fund_list in funds.items():\n",
        "    mean = sector_means[sector]\n",
        "    std = sector_stds[sector]\n",
        "    for fund in fund_list:\n",
        "        returns = np.random.normal(loc=mean, scale=std, size=months_per_fund)\n",
        "        # clip returns roughly between -0.02 and 0.03\n",
        "        returns = np.clip(returns, -0.02, 0.03)\n",
        "        for ret in returns:\n",
        "            rows.append([fund, sector, round(ret, 4)])\n",
        "\n",
        "df = pd.DataFrame(rows, columns=['Fund', 'Sector', 'Monthly_Return'])\n",
        "df.to_csv('synthetic_mutual_fund_data.csv', index=False)\n",
        "print(f\"Generated {len(df)} rows of synthetic mutual fund data.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}